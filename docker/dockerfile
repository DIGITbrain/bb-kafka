# build image: docker build -t apache-kafka:3.0.0 .
# docker run -d --rm --name kafka --rm -e ADVERTISED_IP=xxx.xxx.xxx.xxx -p 9093:9093/tcp kafka-image:3.0.0

FROM ubuntu:20.04

# package pre-requisites
RUN apt-get update && apt-get install -y openjdk-11-jdk-headless wget

# create user 'kafka'
RUN useradd -ms /bin/bash kafka
RUN passwd kafka -l
USER kafka
WORKDIR /home/kafka

# download kafka binaries
RUN wget https://dlcdn.apache.org/kafka/3.0.0/kafka_2.13-3.0.0.tgz && mkdir kafka && tar zxvf kafka_2.13-3.0.0.tgz -C kafka --strip 1 && rm kafka_2.13-3.0.0.tgz

# set environment variables (java home and heap size)
ENV JAVA_HOME=/usr/lib/jvm/java-1.11.0-openjdk-amd64
ENV KAFKA_HEAP_OPTS="-Xms1g -Xmx2g"

# create symlinks and data dir
RUN ln -s kafka/config; ln -s kafka/logs; ln -s kafka/bin
RUN mkdir data

# copy server certificates (can be overridden with volume mounts)
RUN mkdir /home/kafka/certificates
COPY ./certificates/kafka-server.keystore.jks /home/kafka/certificates/
COPY ./certificates/kafka-server.truststore.jks /home/kafka/certificates/

# alter zookeeper.properties
RUN sed -i 's/\/tmp\/zookeeper/\/home\/kafka\/data/g' config/zookeeper.properties

# alter (kafka) server.properties: max. 24 hours retention time, max. 10GB total space for logs, topic creation enabled, SSL
RUN sed -i 's/\/tmp\/kafka-logs/\/home\/kafka\/data/g' config/server.properties; \
    sed -i 's/log.retention.hours=168/log.retention.hours=24/g' config/server.properties; \
    echo "\n### new part ###" >> config/server.properties; \
    echo "delete.topic.enable = true" >> config/server.properties; \
    echo "log.retention.bytes=10737418240" >> config/server.properties; \
#   echo "listeners=PLAINTEXT://:9092,SSL://:9093" >> config/server.properties; \
    echo "listeners=EXTERNAL://:9093,INTERNAL://:9092" >> config/server.properties; \
    echo "listener.security.protocol.map=EXTERNAL:SSL,INTERNAL:PLAINTEXT" >> config/server.properties; \
    echo "inter.broker.listener.name=INTERNAL" >> config/server.properties; \
    echo "ssl.client.auth=required" >> config/server.properties; \
    echo "ssl.keystore.location=/home/kafka/certificates/kafka-server.keystore.jks" >> config/server.properties; \
    echo "ssl.keystore.password=keystorepass" >> config/server.properties; \
    echo "ssl.keystore.type=PKCS12" >> config/server.properties; \
    echo "ssl.truststore.location=/home/kafka/certificates/kafka-server.truststore.jks" >> config/server.properties; \
    echo "ssl.truststore.password=truststorepass" >> config/server.properties; \
    echo "ssl.truststore.type=PKCS12" >> config/server.properties;

#   echo "advertised.listeners=PLAINTEXT://ADVERTISED_IP:PLAINTEXT_PORT,SSL://ADVERTISED_IP:SSL_PORT" >> config/server.properties; \

# create start-kafka.sh wrapper that starts zookeeper and kafka (and injects environment parameters: ADVERTISED_IP, PLAINTEXT_PORT, SSL_PORT)
RUN echo "#!/bin/bash" >> start-kafka.sh; \
    echo "if [[ -z \"\${ADVERTISED_IP}\" ]]; then ADVERTISED_IP=\"127.0.0.1\"; fi" >> start-kafka.sh; \
    echo "if [[ -z \"\${SSL_PORT}\" ]]; then SSL_PORT=\"9093\"; fi" >> start-kafka.sh; \
    echo "echo \"advertised.listeners=EXTERNAL://\$ADVERTISED_IP:\$SSL_PORT,INTERNAL://:9092\" >> config/server.properties" >> start-kafka.sh; \
    echo "/home/kafka/bin/zookeeper-server-start.sh /home/kafka/config/zookeeper.properties &" >> start-kafka.sh; \
#   echo "sed -i 's/ADVERTISED_IP/'\$ADVERTISED_IP'/g' config/server.properties" >> start-kafka.sh; \
#   echo "sed -i 's/PLAINTEXT_PORT/'\$PLAINTEXT_PORT'/g' config/server.properties" >> start-kafka.sh; \
#   echo "sed -i 's/SSL_PORT/'\$SSL_PORT'/g' config/server.properties" >> start-kafka.sh; \
    echo "/home/kafka/bin/kafka-server-start.sh /home/kafka/config/server.properties &" >> start-kafka.sh; \
    echo "wait -n" >> start-kafka.sh; \
    echo "exit $?" >> start-kafka.sh;
RUN chmod +x start-kafka.sh

# update Kafka and Zookeeper loggers to limit disk space
# turn off TRACE for Kafka controller logs
RUN sed -i 's/log4j.logger.kafka.controller=TRACE/log4j.logger.kafka.controller=INFO/g' config/log4j.properties
# replace Kafka's DailyRollingFileAppender with RollingFileAppender, set maxBackupIndex to 10 (default maxFileSize 10MB)
RUN sed -i 's/org.apache.log4j.DailyRollingFileAppender/org.apache.log4j.RollingFileAppender/g' config/log4j.properties
RUN echo "\n### new part ###" >> config/log4j.properties; \
    echo "log4j.appender.kafkaAppender.maxBackupIndex=10" >> config/log4j.properties; \
    echo "log4j.appender.stateChangeAppender.maxBackupIndex=10" >> config/log4j.properties; \
    echo "log4j.appender.cleanerAppender.maxBackupIndex=10" >> config/log4j.properties; \
    echo "log4j.appender.controllerAppender.maxBackupIndex=10" >> config/log4j.properties; \
    echo "log4j.appender.authorizerAppender.maxBackupIndex=10" >> config/log4j.properties;
# Zookeeper defaults are ok: log4j.appender.ROLLINGFILE.MaxFileSize=256MB, log4j.appender.ROLLINGFILE.MaxBackupIndex=20

# run zookeeper and kafka at startup (ENTRYPOINT?)
CMD /home/kafka/start-kafka.sh

